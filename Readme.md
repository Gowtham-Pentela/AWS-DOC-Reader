# TitanRAG on AWS 
### - End-to-End Retrieval-Augmented Generation

This project is a **serverless RAG pipeline** fully built on **AWS managed services**.
You upload PDFs â†’ theyâ€™re converted into text â†’ chunked & embedded â†’ stored in Aurora PostgreSQL with **pgvector** â†’ queried via **SageMaker + Bedrock Titan models** â†’ exposed through **API Gateway + Lambda** â†’ and finally connected to a **Streamlit web UI** where you can ask questions.

---

## ğŸ”¹ Architecture

```text
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   Upload PDF â†’   â”‚   S3 Input   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Trigger
                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Lambda     â”‚  
                  â”‚  (chunk +    â”‚
                  â”‚  embed text) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Aurora (RDS) â”‚  
                  â”‚ + pgvector   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ Retrieval + Generation â”‚
             â”‚   SageMaker Endpoint   â”‚
             â”‚ (Titan Embed + Titan   â”‚
             â”‚ Text Express)          â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                  â”‚   Lambda    â”‚  
                  â”‚   Adapter   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                  â”‚ API Gateway â”‚ â†’ Public HTTPS endpoint
                  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                  â”‚  Streamlit  â”‚ (frontend)
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¹ Features

* **ğŸ“‚ Upload PDFs** â†’ automatically chunked & embedded
* **ğŸ§® Titan Embeddings v2** â†’ semantic search ready
* **ğŸ—„ï¸ Aurora PostgreSQL (pgvector)** â†’ stores vectors + chunks
* **ğŸ¤– Titan Text Express** â†’ synthesizes natural language answers
* **âš¡ SageMaker Serverless** â†’ no idle costs
* **ğŸŒ API Gateway + Lambda** â†’ clean HTTPS endpoint
* **ğŸ–¥ï¸ Streamlit UI** â†’ ask questions interactively in browser

---

## ğŸ”¹ Setup Guide

### 1. Prerequisites

* AWS account 
* AWS CLI installed & configured
* Python 3.10+ locally

---

### 2. Create S3 Buckets

* One bucket for **raw PDFs** (`ra-docs-input-*`)
* One bucket for **processed TXT + models** (`ra-docs-output-*`)

---

### 3. Aurora PostgreSQL + pgvector

1. Create an **Aurora PostgreSQL Serverless v2** cluster.
2. Enable **RDS Data API**.
3. Connect to DB and create:

   * `vector` extension
   * `ra_chunks` table
   * HNSW index on embeddings

---

### 4. Ingestion Lambda

* Triggered on **S3 input bucket**.
* Extracts text from PDF, chunks it, generates embeddings (Titan), inserts into Aurora.
* Outputs chunked TXT into output bucket.

---

### 5. SageMaker Endpoint

* Package inference code & upload to S3 as a `.tar.gz`.
* Create **SageMaker Model** with:

  * Image: scikit-learn container
  * Env vars: DB cluster ARN, secret ARN, Bedrock model IDs, etc.
* Create **serverless endpoint config** and deploy endpoint.
* Test via CLI (`invoke-endpoint`).

---

### 6. API Gateway + Lambda Adapter

* Create a Lambda that forwards API calls to the SageMaker endpoint.
* Grant it `sagemaker:InvokeEndpoint`.
* Create an **HTTP API Gateway**:

  * Route: `POST /query`
  * Integration: Lambda
  * Enable **CORS** (`*` origin, POST + OPTIONS).
* Deploy a stage (e.g. `prod`).
* Copy the **Invoke URL** for frontend use.

---

### 7. Streamlit Frontend

* A simple UI where users type a question, send it to API Gateway, and get back an answer + citations.
* Run locally with `streamlit run app.py`.
* API calls use the Invoke URL from API Gateway.

---

## ğŸ”¹ Example Flow

1. Upload `Attention.pdf` into input bucket.
2. Lambda processes â†’ embeddings stored in Aurora.
3. User opens Streamlit â†’ types:

   > â€œSummarize key points from Attentionâ€
4. API Gateway â†’ Lambda â†’ SageMaker â†’ Aurora â†’ Bedrock Titan â†’ answer returned.
5. Streamlit displays answer + source citations.

---

## Results
 ![Sample Result](result.png) 
## ğŸ”¹ Next Steps

* ğŸ”’ Add auth (Cognito or IAM auth in API Gateway)
* ğŸ“Š Add metrics in CloudWatch
* â˜ï¸ Host Streamlit via App Runner or ECS for production

---

